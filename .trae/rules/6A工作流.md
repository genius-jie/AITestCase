# 6A工作流生成测试用例

## 阶段1: Align（需求分析）
**目标：** 从需求文档中提取清晰、可测试的功能点和验收标准

### 要做的事：
1. 分析用户提供的需求文档，提取：
   - 核心功能点
   - 业务规则
   - 验收标准
   - 边界条件
2. 创建 `AI测试分析交付物/任务名/1_REQUIREMENT_ANALYSIS_任务名.md`，记录：
   - 原始需求（用户原话）
   - 提取的功能点列表
   - 业务规则明细
   - 验收标准
   - 疑问清单（需要用户确认的点）
3. 优先根据需求文档做假设，不确定时主动中断询问
4. 最后生成 `AI测试分析交付物/任务名/1_VALIDATED_REQUIREMENTS_任务名.md`，包含双方确认后的需求和验收标准

### 必须达标：
- 需求清晰无歧义
- 功能点提取完整
- 验收标准明确可测

## 阶段2: Architect（测试架构设计）
**目标：** 设计测试策略和架构，确定测试范围和方法

### 要做的事：
基于上一阶段的验证需求文档，设计测试架构，输出 `AI测试分析交付物/任务名/2_TEST_ARCHITECTURE_任务名.md`，包括：

- 测试策略（黑盒/白盒/灰盒）
- 测试范围（功能/非功能/接口）
- 测试维度覆盖（正例、反例、边界、异常、并发、鲁棒性、稳定性、操作体验性、兼容性、安全性）
- 测试工具建议
- 测试用例组织结构

### 原则：
- 覆盖所有关键测试维度
- 符合项目实际情况
- 可扩展性强

## 阶段3: Atomize（测试任务拆分）
**目标：** 拆分模块和功能，为每个功能点设计测试

### 要做的事：
基于测试架构文档，生成 `AI测试分析交付物/任务名/3_TEST_TASKS_任务名.md`，执行：

1. 模块拆分：将系统拆分为可独立测试的模块
2. 功能拆分：将每个模块拆分为具体功能点
3. 为每个功能点分配测试维度
4. 建立功能点与测试维度的映射关系

同时输出测试任务依赖图（mermaid）。

### 原则：
- 每个功能点都被充分测试
- 测试维度覆盖完整，参考下面的测试维度精准匹配实现方案
- **架构与任务一致性**：确保测试架构中定义的全部维度，在任务拆分阶段均被合理分配，无遗漏。  
- **维度匹配合理性**：依据功能特性精准匹配测试维度，避免"一刀切"，参考测试维度精准匹配实现方案，维度取舍需有明确依据。
- 任务之间依赖清晰

### 测试维度精准匹配实现方案

#### 1. 架构与任务一致性保障措施
- **维度映射表**：为每个功能点创建维度映射表，确保所有测试架构中定义的维度都有明确的功能点与之对应
- **维度覆盖检查清单**：建立标准化的维度覆盖检查清单，在任务拆分完成后进行逐项检查
- **交叉验证机制**：安排不同测试人员对维度分配进行交叉验证，确保无遗漏

#### 2. 维度匹配合理性保障措施
- **功能特性分析法**：
  - 特性识别：分析功能的核心特性（输入、输出、状态、依赖关系）
  - 维度筛选：根据特性选择最相关的测试维度
  - 依据记录：为每个维度的选择提供明确的依据
- **维度优先级矩阵**：
  - 为每个功能点建立维度优先级矩阵
  - 根据功能重要性和风险程度确定维度优先级
  - 确保高优先级功能覆盖更多相关维度
- **差异化覆盖策略**：
  - 根据功能类型（核心/辅助）、用户使用频率、风险程度进行差异化分析
  - 只选择与功能特性相关的维度，避免"一刀切"
  - 为每个维度的取舍提供明确的依据文档

#### 3. 维度匹配示例
| 功能模块 | 功能点 | 匹配维度 | 匹配依据 |
|---------|-------|---------|---------|
| 战斗系统 | 技能释放 | 正例、反例、边界、异常、并发、鲁棒性、稳定性、操作体验性、兼容性、安全性 | 核心战斗功能，涉及用户操作、网络交互、状态管理等多种特性 |
| 背包系统 | 物品存储 | 正例、边界、反例 | 主要涉及容量限制和数据存储，无需并发、稳定性等维度 |
| 社交系统 | 好友添加 | 正例、反例、并发、安全性 | 涉及用户交互和数据安全，需要并发测试防止重复添加

## 阶段4: Approve（测试方案审批）
**目标：** 确认测试方案的完整性和可行性

### 要做的事：
1. 生成测试方案审批文档，汇总：
   - 测试架构设计摘要
   - 测试任务拆分情况
   - 需要确认的关键内容
2. **必须明确中断执行**，向用户展示审批文档内容
3. **等待用户明确回复"确认"后**，才能继续进入下一阶段
4. 如果用户有修改意见，根据意见调整测试方案后重新进入本阶段

### 必须确认的内容：
  - 是否覆盖所有需求？
  - 测试维度是否完整？
  - 测试策略是否可行？
  - 验收标准是否明确？

**重要：** 本阶段必须严格中断执行，直到收到用户的明确确认。

## 阶段5: Automate（测试用例自动生成）
**目标：** 自动生成全面的测试用例和checklist

### 要做的事：
1. 进入本阶段前，**全盘扫描并识别**用户在上阶段（Approve）之后对以下交付物的任何手动修改：
   - `AI测试分析交付物/任务名/1_REQUIREMENT_ANALYSIS_任务名.md`
   - `AI测试分析交付物/任务名/1_VALIDATED_REQUIREMENTS_任务名.md`
   - `AI测试分析交付物/任务名/2_TEST_ARCHITECTURE_任务名.md`
   - `AI测试分析交付物/任务名/3_TEST_TASKS_任务名.md`
   - 功能点与测试维度映射关系
   - 测试任务依赖图（mermaid）
   若发现更新，**以最新内容为准**重新加载测试任务与维度，确保后续生成完全基于最新方案。
2. 按测试任务顺序依次执行：
   - 为每个功能点生成多维度测试用例（正例、反例、边界、异常、并发、鲁棒性、稳定性、操作体验性、兼容性、安全性）
   - 生成结构化的checklist
   - 确保每个测试用例包含：测试类型、优先级、用户输入、系统预期行为、验证方式
   - 按照测试类型排序：先正例、后反例、边界、异常、并发、鲁棒性、稳定性、操作体验性、兼容性、安全性
3. 生成OPML格式的测试用例脑图，确保：
   - 符合XML规范
   - 特殊字符正确转义
   - 层级结构清晰
   - 可直接导入XMind
4. 每完成一个功能点的测试用例生成，在 `AI测试分析交付物/任务名/4_TEST_CASE_PROGRESS_任务名.md` 中记录进度
5. 遇到问题立刻暂停，记录问题详情并询问

### 测试用例规范：
- 每个测试类型至少5项测试用例
- 覆盖所有要求的测试维度
- 涉及状态流转的，采用状态机建模驱动，保证所有状态全部测试到
- 测试用例可执行、可追踪
- 如果测试用例生成文件太大，建议分模块生成，每个模块不超过100条测试用例

## 阶段6: Assess（测试用例评估）
**目标：** 验收测试用例质量，确保符合要求

### 要做的事：
1. 整体验收测试用例：
   - 所有需求已覆盖
   - 所有测试维度已覆盖
   - 测试用例符合规范
   - OPML文件可正常导入XMind
2. 生成最终测试用例报告 `AI测试分析交付物/任务名/5_FINAL_TEST_CASES_任务名.md`
3. 生成测试用例交付物：
   - OPML格式的测试用例脑图
   - 测试用例文档
4. 询问用户是否需要进一步优化
